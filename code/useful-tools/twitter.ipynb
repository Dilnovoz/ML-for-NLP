{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to extract twitter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "bearer_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token=bearer_token, consumer_key=consumer_key, consumer_secret=consumer_secret, access_token=access_token, access_token_secret=access_token_secret, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets_keyword(keyword):\n",
    "\n",
    "    all_tweets = []\n",
    "    for response in tweepy.Paginator(client.search_recent_tweets,\n",
    "                                    query = f\"{keyword} -is:retweet -is:reply\",\n",
    "                                    user_fields = ['username', 'public_metrics'],\n",
    "                                    tweet_fields = ['created_at', 'public_metrics', 'text'],\n",
    "                                    expansions = ['author_id', 'referenced_tweets.id'],\n",
    "                                    #  start_time = '2022-03-14T00:00:00Z',\n",
    "                                    #  end_time = '2021-01-21T00:00:00Z',\n",
    "                                    max_results=100):\n",
    "        time.sleep(1)\n",
    "        all_tweets.append(response)\n",
    "    \n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets_info(all_tweets):\n",
    "\n",
    "    result = []\n",
    "    user_dict = {}\n",
    "    # Loop through each response object\n",
    "    for response in all_tweets:\n",
    "        # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "        for user in response.includes['users']:\n",
    "            user_dict[user.id] = {'username': user.username, \n",
    "                                'followers': user.public_metrics['followers_count'],\n",
    "                                'tweets': user.public_metrics['tweet_count'],\n",
    "                                'description': user.description,\n",
    "                                'location': user.location\n",
    "                                }\n",
    "                                        \n",
    "        for tweet in response.data:\n",
    "            # For each tweet, find the author's information\n",
    "            author_info = user_dict[tweet.author_id]\n",
    "\n",
    "            try:\n",
    "                reference_status = tweet.referenced_tweets[0].type\n",
    "            except:\n",
    "                reference_status = None\n",
    "            \n",
    "            # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "            result.append({'author_id': tweet.author_id, \n",
    "                        'username': author_info['username'],\n",
    "                        'author_followers': author_info['followers'],\n",
    "                        'author_tweets': author_info['tweets'],\n",
    "                        'author_description': author_info['description'],\n",
    "                        'author_location': author_info['location'],\n",
    "                        'text': tweet.text,\n",
    "                        'created_at': tweet.created_at,\n",
    "                        'retweets': tweet.public_metrics['retweet_count'],\n",
    "                        'replies': tweet.public_metrics['reply_count'],\n",
    "                        'likes': tweet.public_metrics['like_count'],\n",
    "                        'quote_count': tweet.public_metrics['quote_count'],\n",
    "                        'tweet_id': tweet.id,        \n",
    "                        'reference_status': reference_status\n",
    "                        })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The New York Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = get_all_tweets_keyword(\"from: nytimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_all_tweets_info(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df.to_csv(\"nytimes_all_tweets.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50e6e71039678dc7652134259ab9c4aeb670039fc42bbd0867810ed67d242f6c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
